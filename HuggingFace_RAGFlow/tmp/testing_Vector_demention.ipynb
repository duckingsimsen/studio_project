{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf4b982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 임베딩 모델은 지금 쓰는 거 아무거나 넣어도 괜찮음 (차원 확인만 할 거니까)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# 벡터 DB 로드\n",
    "vector_store = FAISS.load_local(\n",
    "    folder_path=\".\",  # ← .faiss / .pkl 파일이 있는 폴더\n",
    "    embeddings=embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# 차원 출력\n",
    "print(\"FAISS index dimension:\", vector_store.index.d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64eb6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 문서 수: 708\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69e71bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 개수: 708\n",
      "차원 수: 1024\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.read_index(\"index.faiss\")\n",
    "print(f\"벡터 개수: {index.ntotal}\")\n",
    "print(f\"차원 수: {index.d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c85e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\studio_class\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find document for id 219, got ID 219 not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      4\u001b[39m embedding = HuggingFaceEmbeddings(model_name=\u001b[33m\"\u001b[39m\u001b[33mnlpai-lab/KURE-v1\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# 저장 시 사용한 것과 동일한 임베딩 모델\u001b[39;00m\n\u001b[32m      6\u001b[39m db = FAISS.load_local(\n\u001b[32m      7\u001b[39m     folder_path=\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# index.faiss, index.pkl이 있는 폴더\u001b[39;00m\n\u001b[32m      8\u001b[39m     embeddings=embedding,\n\u001b[32m      9\u001b[39m     allow_dangerous_deserialization=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m results = \u001b[43mdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m넌 어떤 박물관의 챗봇이야?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(r.page_content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\studio_class\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:643\u001b[39m, in \u001b[36mFAISS.similarity_search\u001b[39m\u001b[34m(self, query, k, filter, fetch_k, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    624\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    625\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    629\u001b[39m     **kwargs: Any,\n\u001b[32m    630\u001b[39m ) -> List[Document]:\n\u001b[32m    631\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[32m    632\u001b[39m \n\u001b[32m    633\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    641\u001b[39m \u001b[33;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[32m    642\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     docs_and_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\studio_class\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:516\u001b[39m, in \u001b[36mFAISS.similarity_search_with_score\u001b[39m\u001b[34m(self, query, k, filter, fetch_k, **kwargs)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[32m    500\u001b[39m \n\u001b[32m    501\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    513\u001b[39m \u001b[33;03m    L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[32m    514\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    515\u001b[39m embedding = \u001b[38;5;28mself\u001b[39m._embed_query(query)\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score_by_vector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\studio_class\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:430\u001b[39m, in \u001b[36mFAISS.similarity_search_with_score_by_vector\u001b[39m\u001b[34m(self, embedding, k, filter, fetch_k, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m doc = \u001b[38;5;28mself\u001b[39m.docstore.search(_id)\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc, Document):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find document for id \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m filter_func(doc.metadata):\n",
      "\u001b[31mValueError\u001b[39m: Could not find document for id 219, got ID 219 not found."
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"nlpai-lab/KURE-v1\")  # 저장 시 사용한 것과 동일한 임베딩 모델\n",
    "\n",
    "db = FAISS.load_local(\n",
    "    folder_path=\".\",  # index.faiss, index.pkl이 있는 폴더\n",
    "    embeddings=embedding,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "results = db.similarity_search(\"넌 어떤 박물관의 챗봇이야?\", k=3)\n",
    "for r in results:\n",
    "    print(r.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d494dac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 문서 수: 708\n",
      "벡터 수: 708\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"nlpai-lab/KURE-v1\")\n",
    "db = FAISS.load_local(\".\", embedding, allow_dangerous_deserialization=True)\n",
    "\n",
    "print(\"저장된 문서 수:\", len(db.docstore._dict))\n",
    "print(\"벡터 수:\", db.index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9461ba29",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Document\nmetadata\n  Input should be a valid dictionary [type=dict_type, input_value={Ellipsis}, input_type=set]\n    For further information visit https://errors.pydantic.dev/2.11/v/dict_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m docs = [\u001b[43mDocument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m넌 어떤 박물관의 챗봇이야?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m      6\u001b[39m embedding = HuggingFaceEmbeddings(model_name=\u001b[33m\"\u001b[39m\u001b[33mnlpai-lab/KURE-v1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m db = FAISS.from_documents(docs, embedding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\studio_class\\Lib\\site-packages\\langchain_core\\documents\\base.py:289\u001b[39m, in \u001b[36mDocument.__init__\u001b[39m\u001b[34m(self, page_content, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Pass page_content in as positional or named arg.\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# my-py is complaining that page_content is not defined on the base class.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# Here, we're relying on pydantic base class to handle the validation.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\studio_class\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\studio_class\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Document\nmetadata\n  Input should be a valid dictionary [type=dict_type, input_value={Ellipsis}, input_type=set]\n    For further information visit https://errors.pydantic.dev/2.11/v/dict_type"
     ]
    }
   ],
   "source": [
    "# 예시: 저장할 때\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "docs = [Document(page_content=\"넌 어떤 박물관의 챗봇이야?\", metadata={...})]\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"nlpai-lab/KURE-v1\")\n",
    "db = FAISS.from_documents(docs, embedding)\n",
    "db.save_local(\"faiss_db\")  # index.faiss + index.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6aab922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 수: 708\n",
      "벡터 수: 708\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"nlpai-lab/KURE-v1\")\n",
    "db = FAISS.load_local(\".\", embedding, allow_dangerous_deserialization=True)\n",
    "\n",
    "print(\"문서 수:\", len(db.docstore._dict))  # metadata 포함 문서 수\n",
    "print(\"벡터 수:\", db.index.ntotal)        # 벡터 인덱스 수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "061ec12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docstore keys (샘플): [0, 1, 2, 3, 4]\n",
      "id_map 샘플: [(0, '0'), (1, '1'), (2, '2'), (3, '3'), (4, '4')]\n"
     ]
    }
   ],
   "source": [
    "print(\"docstore keys (샘플):\", list(db.docstore._dict.keys())[:5])\n",
    "print(\"id_map 샘플:\", list(db.index_to_docstore_id.items())[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34abef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docstore 내부 dict 키를 모두 str로 변환\n",
    "db.docstore._dict = {str(k): v for k, v in db.docstore._dict.items()}\n",
    "db.save_local(\"faiss_db_fixed\")  # 새 디렉토리에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14033174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. 미래 도서관 비전 및 가상도서관 구축·운영 방안 \n",
      "차승현/한국과학기술원 문화기술대학원 교수\n",
      "111\n",
      "인공지능과 사서 \n",
      "챗GPT에게 물어본 인공지능 시대의 도서관과 사서\n",
      "이권우/도서 평론가\n",
      "131\n",
      "대담\n",
      "뉴노멀 시대의 도서관, 그리고 사서\n",
      "사회자: 박옥남/상명대학교 문헌정보학과 교수 \n",
      "대담자: 오영진/서울과학기술대학교 융합교양학부 초빙조교수\n",
      "정재영/서강대학교 로욜라도서관 정보봉사팀장\n",
      "주영하/서울특별시교육청양천도서관 독서문화진흥과 팀장\n",
      "147\n",
      "추천 자료 \n",
      "171\n",
      " \n",
      "에필로그 \n",
      "1. 챗GPT가 말한 도서관의 미래 \n",
      "2. 인공지능이 그린 미래의 도서관\n",
      "176\n",
      "※본지에 실린 글의 내용은 집필진의 개인적인 견해로, 국립중앙도서관의 의견이 아님을 밝힙니다.\n",
      "\n",
      "\n",
      "96\n",
      "다\n",
      "시\n",
      " \n",
      "연\n",
      "결\n",
      " \n",
      "사\n",
      "람\n",
      "과\n",
      " \n",
      "기\n",
      "술\n",
      "이\n",
      " \n",
      "공\n",
      "존\n",
      "하\n",
      "는\n",
      " \n",
      "도\n",
      "서\n",
      "관\n",
      ",\n",
      "2층은 ‘미래의 가치를 연결하다’라는 주제 아래 인공지능과 빅데이터를 기반으로 무한한 \n",
      "상상과 창조가 이루어지는 최첨단 미래 독서 공간의 콘셉트로 구성된 공간이다. 실감형 체\n",
      "험관과 디지털 맞춤형 북큐레이션, VR 가상 독서 체험 등을 할 수 있다. \n",
      "2층에서도 역시 여러 로봇이 눈에 띈다. ‘나르미’라는 이름의 로봇은 서랍형과 선반형 \n",
      "두 종류로 운영되는 도서 운반 로봇이다. 선반형은 업무용으로 활용되고 있으며, 서랍형은 \n",
      "고령자나 장애인 등 거동이 불편한 이용자에게 도서를 운반해주기 위해 쓰이고 있다. 서랍\n",
      "형 로봇은 엘리베이터에 탑승하여 층별 책 운반도 할 수 있다. \n",
      "장서 점검 로봇 ‘서치봇’은 낮 동안 서가에 잘못 꽂힌 도서를 밤새 점검해주는 역할을 한\n",
      "다. 점검 후 데이터를 전송하면 사서들이 잘못 꽂힌 책을 바로잡는다. 일반적으로 사서들이 \n",
      "장서 점검을 할 때 일주일 정도의 시간이 걸린다면, 서치봇은 1~2일 만에 소화해낸다.\n",
      "그리고 기술과 예술을 결합한 디지털 갤러리 ‘명화의 세계’도 2층에서 만날 수 있다. \n",
      "2,000여 점의 명화를 소장하고 있으며, 다섯 개의 화면 속에 다양한 명화가 소개되는데 계\n",
      "속 작품들이 바뀌며 전시되기 때문에 지루할 틈이 없다. ‘나만의 발견’은 인공지능 기반의 \n",
      "디지털 맞춤형 북큐레이션이다. 엄선된 도서 2,000여 종의 서지 사항뿐만 아니라 책 속의 \n",
      "핵심 문장 등을 남녀노소 누구나 한눈에 살펴보기 쉽도록 카드형 콘텐츠로 구현했다.\n",
      "[그림 5] 북큐레이션 도서를 전시하는 LIB 서가 \n",
      "[그림 6] 디지털 맞춤형 북큐레이션 ‘나만의 발견’\n",
      "그리고 2층에서는 2022년 문화체육관광부 공모사업에 선정되어 교육청 소속 도서관 \n",
      "최초로 구축한 실감형 체험관 ‘미래의 발견’도 만날 수 있다. 벽면에 부착된 대형 스크린에 \n",
      "공간감이 느껴지는 가상의 서재가 만들어져 있는데, 앞에 놓인 정전식 멀티터치 테이블과 \n",
      "동시에 구동하여 ‘검색의 미래’를 보여준다. 이곳에서는 물리적인 책과 디지털 정보를 접목\n",
      "한 새로운 형태의 인터랙트(Interact) 디지털 북도 체험할 수 있는데, 창원도서관에서는 영\n",
      "\n",
      "\n",
      "94\n",
      "다\n",
      "시\n",
      " \n",
      "연\n",
      "결\n",
      " \n",
      "사\n",
      "람\n",
      "과\n",
      " \n",
      "기\n",
      "술\n",
      "이\n",
      " \n",
      "공\n",
      "존\n",
      "하\n",
      "는\n",
      " \n",
      "도\n",
      "서\n",
      "관\n",
      ",\n",
      "새로운 세계와 만나다\n",
      "‘새로운 세계와 만나다’라는 주제를 표방하는 책담 1층은 사람과 로봇, 자연과 우주, 현\n",
      "실과 가상이 공존하는 곳으로 아날로그와 디지털을 공유하는 소통·문화 공간으로 구성되\n",
      "어 있다. 미래형 도서관에 걸맞게 다양한 종류의 로봇들과 3D 홀로그램을 구축한 점이 특\n",
      "징이다. 곳곳에서 활약하는 여러 종류의 로봇, 대형 입체 영상뿐만 아니라 지리정보 기반\n",
      "의 도서 추천 시스템도 경험할 수 있다. \n",
      "1층에 들어서면 자동 연주 기능이 있는 그랜드피아노의 선율이 방문객을 맞이한다. 평\n",
      "상시에는 자동 연주를 통해 음악이 흘러나오지만, 도서관 기획 공연이 있을 때는 피아니스\n",
      "트의 손을 거쳐 아름다운 멜로디를 뿜어내기도 한다. 피아노 선율과 함께 내부로 들어가면 \n",
      "책담을 안내하는 도슨트 로봇 ‘라봇’이 이용자를 맞이한다. 라봇은 시설 안내, 행사 안내 등 \n",
      "기본적인 기능은 물론 도서관에서 필수적인 도서 검색 기능과 책의 위치 안내, 도서 검색 \n",
      "시 텍스트, 음성인식도 모두 가능한 로봇이다. 라봇과 함께 촬영도 가능하며 스마트폰으로 \n",
      "사진을 전송해주기도 한다. \n",
      "로봇 존 옆에는 증강현실(AR) 영상과 아날로그 모래놀이를 결합한 샌드크래프트가 자\n",
      "리를 잡고 있다. 이곳에서 아이들은 모래를 파고 쌓고 만지는 등 다양한 체감형 활동이 가\n",
      "능하다. 책과 함께하는 공간이 즐겁고 행복하다는 것을 느낄 수 있도록 조성된 공간으로, \n",
      "촉감 발달에도 효과가 있는 샌드크래프트를 통해 아이들이 도서관을 더욱 친숙하게 느낄 \n",
      "수 있다. \n",
      "1층에는 라봇 말고도 여러 로봇이 활동하고 있는데, 대표적으로 ‘아이봇’이 있다. 로봇 \n",
      "존에서 자율주행하는 로봇으로 기본적인 안내를 하는 것은 물론 발레와 모던 댄스 등 다양\n",
      "한 모션으로 음악에 맞춰 춤을 춘다. 아이들과 대화도 가능해 정서 발달에 도움을 주는 로봇\n",
      "이다. ‘에듀봇’은 커뮤니케이션 로봇으로 유아·어린이들과 대화는 물론 코딩 수업도 가능하\n",
      "다. 로봇 존의 천장에서 만날 수 있는 3D 홀로그램은 도서관 로고, 신간 도서 소개, 계절별 \n",
      "감각을 3D 입체 홀로그램으로 표현하는 새로운 방법으로 이용자들의 눈길을 끌고 있다. \n",
      "어린이를 위한 자유 독서 공간 ‘아이누리’ 역시 1층에서 만날 수 있다. 아이누리 중앙에\n",
      "는 책을 읽을 수 있는 ‘아띠뜰’이 있고, 3D 실감 영상으로 아이들의 상상력과 창의력을 높\n",
      "이는 ‘디지털 퍼포먼스 월’이 자리하고 있다. 아띠뜰은 신발을 벗고 들어갈 수 있는 온돌마\n",
      "루 형식으로 되어 있어 집에서 책을 읽는 것처럼 편안함을 느낄 수 있다. 또한 아이누리에\n",
      "는 아이들 눈높이에 맞게 낮은 3단 책장들이 비치되어 있고, 책장에 설치된 디지털 사서 시\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"nlpai-lab/KURE-v1\")\n",
    "db = FAISS.load_local(\n",
    "    folder_path=\"faiss_db_fixed\",\n",
    "    embeddings=embedding,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "results = db.similarity_search(\"넌 어떤 박물관의 챗봇이야?\", k=3)\n",
    "for r in results:\n",
    "    print(r.page_content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studio_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
